{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "import torch\n",
                "from transformers import GPT2Tokenizer, GPT2Model\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.decomposition import PCA\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from scipy import stats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MPS device found!\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "\n",
                "# 检查 MPS 是否可用\n",
                "if torch.backends.mps.is_available():\n",
                "    mps_device = torch.device(\"mps\")\n",
                "    print(\"MPS device found!\")\n",
                "else:\n",
                "    print(\"MPS device not found.\")\n",
                "    mps_device = torch.device(\"cpu\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/jj/84v_jpsx4rj3__y62xh3klxm0000gn/T/ipykernel_61533/1766486254.py:3: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
                        "  bios_data = pickle.load(f)\n"
                    ]
                }
            ],
            "source": [
                "dataset_path = \"bios_train.pkl\"  \n",
                "with open(dataset_path, 'rb') as f:\n",
                "    bios_data = pickle.load(f)\n",
                "\n",
                "# Convert data into pandas dataframe\n",
                "if isinstance(bios_data, list):\n",
                "    bios_df = pd.DataFrame(bios_data)\n",
                "else:\n",
                "    bios_df = bios_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract profession words from BIB dataset classification labels\n",
                "# https://huggingface.co/datasets/LabHC/bias_in_bios\n",
                "\n",
                "profession_list_from_readme = [ \n",
                "    \"accountant\", \"architect\", \"attorney\", \"chiropractor\", \"comedian\", \"composer\", \"dentist\", \"dietitian\", \"dj\",\n",
                "    \"filmmaker\", \"interior_designer\", \"journalist\", \"model\", \"nurse\", \"painter\", \"nurse\", \"paralegal\", \"pastor\", \"personal_trainer\",\n",
                "    \"photographer\", \"physician\", \"poet\", \"professor\", \"psychologist\", \"rapper\", \"software_engineer\", \"surgeon\", \"teacher\",\n",
                "    \"yoga_teacher\" \n",
                "]\n",
                "gender_terms = [\"he\", \"she\", \"man\", \"woman\", \"person\", \"individual\", \"male\", \"female\"] \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load GPT-2 tokenizer and model\n",
                "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
                "model = GPT2Model.from_pretrained('gpt2')\n",
                "\n",
                "# Move model to the appropriate device\n",
                "model = model.to(mps_device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define function to get word embeddings, using average word vectors from GPT-2\n",
                "def get_word_embedding(word, tokenizer, model, device):\n",
                "    \n",
                "    inputs = tokenizer(word, return_tensors=\"pt\").to(device)\n",
                "    outputs = model(**inputs)\n",
                "    # 使用最后隐藏层的第一个 token 的隐藏状态作为词嵌入 (可以尝试其他 pooling 策略)\n",
                "    word_embedding = outputs.last_hidden_state[:, 0, :].mean(dim=0) # 使用 mean pooling\n",
                "    return word_embedding.detach().cpu().numpy() # 移动到 CPU 并转换为 numpy 数组\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Obtain word embeddings for occupational and gender vocabulary\n",
                "profession_embeddings = {\n",
                "    profession: get_word_embedding(profession, tokenizer, model, mps_device)\n",
                "    for profession in profession_list_from_readme\n",
                "}\n",
                "gender_embeddings = {\n",
                "    gender: get_word_embedding(gender, tokenizer, model, mps_device)\n",
                "    for gender in gender_terms\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculating cosine similarity between vocational and gender terms\n",
                "print(\"\\nCosine Similarity between Professions and Gender Terms:\")\n",
                "similarity_scores = {}\n",
                "for profession, profession_emb in profession_embeddings.items():\n",
                "    similarity_scores[profession] = {}\n",
                "    print(f\"\\nProfession: {profession}\")\n",
                "    for gender_term, gender_emb in gender_embeddings.items():\n",
                "        similarity = cosine_similarity(np.array([profession_emb]), np.array([gender_emb]))[0][0]\n",
                "        similarity_scores[profession][gender_term] = similarity\n",
                "        print(f\"  Cosine Similarity with '{gender_term}': {similarity:.4f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PCA downscaling to 2D and visualization \n",
                "profession_names = list(profession_embeddings.keys())\n",
                "embeddings_for_pca = np.array([profession_embeddings[name] for name in profession_names])\n",
                "\n",
                "pca = PCA(n_components=2)\n",
                "pca_result = pca.fit_transform(embeddings_for_pca)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=range(len(profession_names)), cmap='viridis') # 使用颜色区分不同职业\n",
                "for i, profession in enumerate(profession_names):\n",
                "    plt.annotate(profession, xy=(pca_result[i, 0], pca_result[i, 1]), fontsize=8) # 添加职业名称标签\n",
                "plt.title('PCA Projection of Profession Word Embeddings')\n",
                "plt.xlabel('Principal Component 1')\n",
                "plt.ylabel('Principal Component 2')\n",
                "plt.colorbar(label='Profession Index') \n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# WEAT effect size calculation\n",
                "def weat_score(target_words_1, target_words_2, attribute_words_1, attribute_words_2, embeddings):\n",
                "    \"\"\"\n",
                "    Calculates the WEAT effect size.\n",
                "\n",
                "    Args:\n",
                "        target_words_1 (list): Target word set 1\n",
                "        target_words_2 (list): Target word set 2\n",
                "        attribute_words_1 (list): Attribute word set 1 (e.g., male attributes)\n",
                "        attribute_words_2 (list): Attribute word set 2 (e.g., female attributes)\n",
                "        embeddings (dict): Word embedding dictionary {word: embedding}\n",
                "\n",
                "    Returns:\n",
                "        float: WEAT effect size\n",
                "    \"\"\"\n",
                "    def calculate_s(word, A, B, embeddings):\n",
                "        \"\"\"Calculates the association strength of a single word with attribute word sets.\"\"\"\n",
                "        emb_w = embeddings[word]\n",
                "        mean_a = np.mean([embeddings[a] for a in A], axis=0)\n",
                "        mean_b = np.mean([embeddings[b] for b in B], axis=0)\n",
                "        return cosine_similarity(np.array([emb_w]), np.array([mean_a]))[0][0] - cosine_similarity(np.array([emb_w]), np.array([mean_b]))[0][0]\n",
                "\n",
                "    S_diffs = [calculate_s(word, attribute_words_1, attribute_words_2, embeddings)\n",
                "               for word in target_words_1 + target_words_2]\n",
                "\n",
                "    mean_diff_targets = np.mean([calculate_s(word, attribute_words_1, attribute_words_2, embeddings)\n",
                "                                  for word in target_words_1])\n",
                "    std_dev_all_targets = np.std(S_diffs)\n",
                "\n",
                "    if std_dev_all_targets == 0: \n",
                "        effect_size = 0.0\n",
                "    else:\n",
                "        effect_size = (mean_diff_targets - np.mean([calculate_s(word, attribute_words_1, attribute_words_2, embeddings)\n",
                "                                                    for word in target_words_2])) / std_dev_all_targets\n",
                "\n",
                "    return effect_size"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define word sets for WEAT test (redefined based on BLS data and BIB profession list)\n",
                "target_professions_male_stereotype = [\n",
                "    \"architect\", \"attorney\", \"dentist\", \"physician\", \"software_engineer\", \"surgeon\", \"composer\", \"filmmaker\", \"photographer\", \"rapper\"\n",
                "] # Male stereotype professions (based on BLS and stereotypes)\n",
                "target_professions_female_stereotype = [\n",
                "    \"nurse\", \"teacher\", \"dietitian\", \"yoga_teacher\", \"interior_designer\", \"model\", \"paralegal\", \"personal_trainer\"\n",
                "] # Female stereotype professions (based on BLS and stereotypes)\n",
                "attribute_male_terms = [\"he\", \"man\", \"male\"]\n",
                "attribute_female_terms = [\"she\", \"woman\", \"female\"]\n",
                "\n",
                "# Ensure target profession words are in your profession_embeddings dictionary\n",
                "valid_target_professions_male = [p for p in target_professions_male_stereotype if p in profession_embeddings]\n",
                "valid_target_professions_female = [p for p in target_professions_female_stereotype if p in profession_embeddings]\n",
                "\n",
                "# Get a subset of word embeddings, containing only the words used in the WEAT test\n",
                "weat_embeddings = {}\n",
                "for word in valid_target_professions_male + valid_target_professions_female + attribute_male_terms + attribute_female_terms:\n",
                "    if word in profession_embeddings:\n",
                "        weat_embeddings[word] = profession_embeddings[word]\n",
                "    elif word in gender_embeddings:\n",
                "        weat_embeddings[word] = gender_embeddings[word]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run WEAT test and print results\n",
                "if len(valid_target_professions_male) > 0 and len(valid_target_professions_female) > 0 and len(attribute_male_terms) > 0 and len(attribute_female_terms) > 0:\n",
                "    effect_size = weat_score(valid_target_professions_male, valid_target_professions_female, attribute_male_terms, attribute_female_terms, weat_embeddings)\n",
                "    print(f\"\\nWEAT Test Effect Size (Male Stereotype Professions vs. Female Stereotype Professions, Attributes: Male vs. Female): {effect_size:.4f}\")\n",
                "\n",
                "    # Calculate p-value using permutation test\n",
                "    from tqdm import tqdm\n",
                "    import random\n",
                "\n",
                "    def permutation_test(target_words_1, target_words_2, attribute_words_1, attribute_words_2, embeddings, n_permutations=10000):\n",
                "        observed_effect_size = weat_score(target_words_1, target_words_2, attribute_words_1, attribute_words_2, embeddings)\n",
                "        combined_words = target_words_1 + target_words_2\n",
                "        num_greater = 0\n",
                "\n",
                "        for _ in tqdm(range(n_permutations), desc=\"Permutation Test\"):\n",
                "            random.shuffle(combined_words)\n",
                "            permuted_target_1 = combined_words[:len(target_words_1)]\n",
                "            permuted_target_2 = combined_words[len(target_words_1):]\n",
                "            permuted_effect_size = weat_score(permuted_target_1, permuted_target_2, attribute_words_1, attribute_words_2, embeddings)\n",
                "            if permuted_effect_size >= observed_effect_size:\n",
                "                num_greater += 1\n",
                "\n",
                "        p_value = num_greater / n_permutations\n",
                "        return p_value\n",
                "\n",
                "    p_value = permutation_test(valid_target_professions_male, valid_target_professions_female, attribute_male_terms, attribute_female_terms, weat_embeddings)\n",
                "    print(f\"P-value: {p_value:.4f}\")\n",
                "\n",
                "    # Print individual word association scores\n",
                "    print(\"\\nIndividual word association scores:\")\n",
                "    for word in valid_target_professions_male + valid_target_professions_female:\n",
                "        s = calculate_s(word, attribute_male_terms, attribute_female_terms, weat_embeddings)\n",
                "        print(f\"  {word}: {s:.4f}\")\n",
                "\n",
                "else:\n",
                "    print(\"\\nWarning: Incomplete word sets for WEAT test. Please check that target professions and attribute words are included in the embedding dictionary.\")\n",
                "    print(\"Valid male stereotype professions:\", valid_target_professions_male)\n",
                "    print(\"Valid female stereotype professions:\", valid_target_professions_female)\n",
                "\n",
                "print(\"\\nExperiment 1 code execution completed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llm_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}