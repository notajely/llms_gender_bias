{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "c783be07",
            "metadata": {},
            "source": [
                "# Notebook 7: Semantic Clustering Analysis and Visualization\n",
                "\n",
                "**Objective:** Perform unsupervised clustering (KMeans, k=2) on the contextualized occupation embeddings and visualize the results using Principal Component Analysis (PCA). This involves:\n",
                "1. Loading the contextual embeddings and corresponding metadata (occupation names, stereotype labels) generated in Notebook 6.\n",
                "2. Performing KMeans clustering to partition the occupations into two groups.\n",
                "3. Applying PCA to reduce the dimensionality of the embeddings to 2D for visualization.\n",
                "4. Creating a scatter plot of the PCA results, coloring points by gender stereotype and marking cluster centroids (similar to Figure 7).\n",
                "5. Analyzing the composition of the resulting clusters."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eeb4acf9",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "7d3a8464",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.metrics import silhouette_score # Optional: To evaluate clustering\n",
                "from pathlib import Path\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a048ab04",
            "metadata": {},
            "source": [
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "4650d0fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Paths ---\n",
                "# Get project root assuming the notebook is in 'notebooks' directory\n",
                "current_dir = Path.cwd()\n",
                "project_root = current_dir.parent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "6f08a247",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Input files (from Notebook 6 outputs)\n",
                "CLUSTER_RESULTS_DIR = project_root / 'results' / 'semantic_clustering'\n",
                "CLUSTER_METADATA_CSV = CLUSTER_RESULTS_DIR / 'clustering_metadata.csv'\n",
                "CLUSTER_EMBEDDINGS_NPZ = CLUSTER_RESULTS_DIR / 'clustering_contextual_embeddings.npz'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "d3043ee5",
            "metadata": {
                "lines_to_next_cell": 2
            },
            "outputs": [],
            "source": [
                "# Output file\n",
                "PCA_PLOT_OUTPUT_PNG = CLUSTER_RESULTS_DIR / 'clustering_pca_plot_figure7.png'\n",
                "CLUSTERING_RESULTS_CSV = CLUSTER_RESULTS_DIR / 'clustering_analysis_results.csv' # Save final df with clusters/pca"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "3d228ad5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Clustering Parameters ---\n",
                "NUM_CLUSTERS = 2\n",
                "RANDOM_SEED = 42 # For reproducibility of KMeans"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "3a089eda",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Plotting Parameters ---\n",
                "# Define colors for stereotype labels (adjust as needed, ensure keys match labels in metadata csv)\n",
                "# Based on Figure 7 legend in paper and provided scripts\n",
                "STEREOTYPE_COLORS = {\n",
                "    'male-stereotyped': '#1f77b4',      # Blue\n",
                "    'male-stereotyped (proxy)': '#aec7e8',  # Lighter Blue (or same blue)\n",
                "    'neutral': '#7f7f7f',               # Gray\n",
                "    'neutral (proxy)': '#bdbdbd',       # Lighter Gray (or same gray)\n",
                "    'female-stereotyped': '#d62728',    # Red\n",
                "    # Add other categories if present in your metadata\n",
                "}\n",
                "CENTROID_MARKER = 'X'\n",
                "CENTROID_COLOR = 'black'\n",
                "CENTROID_SIZE = 200"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "37b77346",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create results directory if it doesn't exist\n",
                "CLUSTER_RESULTS_DIR.mkdir(parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bf5a61ec",
            "metadata": {},
            "source": [
                "## 3. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "7725e627",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded metadata for 26 occupations.\n"
                    ]
                }
            ],
            "source": [
                "# Load metadata\n",
                "try:\n",
                "    df_meta = pd.read_csv(CLUSTER_METADATA_CSV)\n",
                "    print(f\"Loaded metadata for {len(df_meta)} occupations.\")\n",
                "    if 'occupation' not in df_meta.columns or 'bls_label' not in df_meta.columns:\n",
                "         raise ValueError(\"Metadata CSV must contain 'occupation' and 'bls_label' columns.\")\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: Metadata file not found at {CLUSTER_METADATA_CSV}\")\n",
                "    print(\"Please ensure Notebook 6 ran successfully.\")\n",
                "    raise\n",
                "except Exception as e:\n",
                "    print(f\"Error loading metadata CSV: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "043a580e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 26 embeddings.\n"
                    ]
                }
            ],
            "source": [
                "# Load embeddings\n",
                "try:\n",
                "    embeddings_data = np.load(CLUSTER_EMBEDDINGS_NPZ, allow_pickle=True)\n",
                "    # Convert NpzFile items to a standard dictionary {occupation_name: embedding}\n",
                "    embeddings_dict = {key: embeddings_data[key] for key in embeddings_data.files}\n",
                "    print(f\"Loaded {len(embeddings_dict)} embeddings.\")\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: Embeddings file not found at {CLUSTER_EMBEDDINGS_NPZ}\")\n",
                "    print(\"Please ensure Notebook 6 ran successfully.\")\n",
                "    raise\n",
                "except Exception as e:\n",
                "    print(f\"Error loading embeddings file: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "cd102ac0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Align Embeddings with Metadata ---\n",
                "# Create the embedding matrix in the *same order* as the dataframe\n",
                "ordered_embeddings = []\n",
                "missing_embeddings = []\n",
                "occupation_order = df_meta['occupation'].tolist() # Get order from DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "767fd39e",
            "metadata": {},
            "outputs": [],
            "source": [
                "for occ in occupation_order:\n",
                "    if occ in embeddings_dict:\n",
                "        ordered_embeddings.append(embeddings_dict[occ])\n",
                "    else:\n",
                "        missing_embeddings.append(occ)\n",
                "        ordered_embeddings.append(np.zeros(list(embeddings_dict.values())[0].shape)) # Append zeros or handle differently"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "b202b698",
            "metadata": {},
            "outputs": [],
            "source": [
                "if missing_embeddings:\n",
                "    print(f\"Warning: Embeddings not found for {len(missing_embeddings)} occupations listed in metadata:\")\n",
                "    print(missing_embeddings)\n",
                "    print(\"These occupations will likely have zero vectors and might affect clustering/PCA.\")\n",
                "    # Optional: Filter df_meta to only include occupations with embeddings\n",
                "    # df_meta = df_meta[~df_meta['occupation'].isin(missing_embeddings)].reset_index(drop=True)\n",
                "    # Re-extract ordered embeddings if df_meta was filtered... (logic gets more complex)\n",
                "    # For now, proceeding with zeros for missing ones."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "7dda7978",
            "metadata": {},
            "outputs": [],
            "source": [
                "embedding_matrix = np.array(ordered_embeddings)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "b7bea068",
            "metadata": {
                "lines_to_next_cell": 2
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Aligned embedding matrix shape: (26, 768)\n"
                    ]
                }
            ],
            "source": [
                "# Verify shapes\n",
                "if embedding_matrix.shape[0] != len(df_meta):\n",
                "    raise ValueError(f\"Mismatch in number of metadata rows ({len(df_meta)}) and embeddings ({embedding_matrix.shape[0]}) after alignment.\")\n",
                "print(f\"Aligned embedding matrix shape: {embedding_matrix.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "65100ae3",
            "metadata": {},
            "source": [
                "## 4. Perform KMeans Clustering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "4fe02d90",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Assigned occupations to 2 clusters.\n",
                        "Silhouette Score: 0.3661 (higher is generally better, closer to 1)\n"
                    ]
                }
            ],
            "source": [
                "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=RANDOM_SEED, n_init=10) # n_init='auto' in newer sklearn\n",
                "try:\n",
                "    cluster_labels = kmeans.fit_predict(embedding_matrix)\n",
                "    centroids = kmeans.cluster_centers_\n",
                "\n",
                "    # Add cluster labels to the DataFrame\n",
                "    df_meta['cluster'] = cluster_labels\n",
                "    print(f\"Assigned occupations to {NUM_CLUSTERS} clusters.\")\n",
                "\n",
                "    # Optional: Calculate and print Silhouette Score\n",
                "    try:\n",
                "        silhouette_avg = silhouette_score(embedding_matrix, cluster_labels)\n",
                "        print(f\"Silhouette Score: {silhouette_avg:.4f} (higher is generally better, closer to 1)\")\n",
                "    except ValueError:\n",
                "        # Silhouette score requires at least 2 unique labels and >1 sample per label\n",
                "        print(\"Could not calculate Silhouette Score (possibly only one cluster assigned or too few samples).\")\n",
                "        \n",
                "except Exception as e:\n",
                "    print(f\"Error during KMeans clustering: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ec65a957",
            "metadata": {},
            "source": [
                "## 5. Perform PCA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "e1e9de00",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "PCA transformation complete.\n",
                        "Explained Variance Ratio - PC1: 0.6978, PC2: 0.0981\n",
                        "Total Explained Variance (2 components): 0.7959\n"
                    ]
                }
            ],
            "source": [
                "pca = PCA(n_components=2, random_state=RANDOM_SEED)\n",
                "try:\n",
                "    pca_results = pca.fit_transform(embedding_matrix)\n",
                "    # Also transform the centroids\n",
                "    centroid_pca = pca.transform(centroids)\n",
                "\n",
                "    # Add PCA components to the DataFrame\n",
                "    df_meta['PC1'] = pca_results[:, 0]\n",
                "    df_meta['PC2'] = pca_results[:, 1]\n",
                "    print(\"PCA transformation complete.\")\n",
                "\n",
                "    # Print explained variance\n",
                "    explained_variance = pca.explained_variance_ratio_\n",
                "    print(f\"Explained Variance Ratio - PC1: {explained_variance[0]:.4f}, PC2: {explained_variance[1]:.4f}\")\n",
                "    print(f\"Total Explained Variance (2 components): {sum(explained_variance):.4f}\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"Error during PCA: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c05712f1",
            "metadata": {},
            "source": [
                "## 6. Save Clustering and PCA Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "4b0395a5",
            "metadata": {
                "lines_to_next_cell": 2
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Saving combined results (metadata, cluster, PCA) to /Users/jessie/Documents/Projects/master_thesis_llms_bias/results/semantic_clustering/clustering_analysis_results.csv...\n",
                        "Combined results saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "print(f\"\\nSaving combined results (metadata, cluster, PCA) to {CLUSTERING_RESULTS_CSV}...\")\n",
                "try:\n",
                "    df_meta.to_csv(CLUSTERING_RESULTS_CSV, index=False, encoding='utf-8')\n",
                "    print(\"Combined results saved successfully.\")\n",
                "except Exception as e:\n",
                "    print(f\"Error saving combined results: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34b83d83",
            "metadata": {},
            "source": [
                "## 7. Generate PCA Scatter Plot (Figure 7)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "e305e6e6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Generating PCA scatter plot (replicating Figure 7)...\n",
                        "\n",
                        "PCA scatter plot saved successfully to /Users/jessie/Documents/Projects/master_thesis_llms_bias/results/semantic_clustering/clustering_pca_plot_figure7.png\n"
                    ]
                }
            ],
            "source": [
                "# ## 7. Generate PCA Scatter Plot (Figure 7)\n",
                "\n",
                "print(\"\\nGenerating PCA scatter plot (replicating Figure 7)...\")\n",
                "\n",
                "if df_meta.empty or 'PC1' not in df_meta.columns or 'PC2' not in df_meta.columns:\n",
                "    print(\"Skipping plot generation: Missing data or PCA coordinates.\")\n",
                "else:\n",
                "    # --- Prepare Data & Colors ---\n",
                "    # Ensure the bls_label column matches the keys in the color map exactly\n",
                "    # Clean up labels slightly if needed (e.g., remove extra spaces)\n",
                "    df_meta['bls_label'] = df_meta['bls_label'].str.strip()\n",
                "\n",
                "    # Define colors exactly matching the target plot's legend\n",
                "    # Using standard color names or hex codes\n",
                "    STEREOTYPE_COLORS_FIG7 = {\n",
                "        'neutral': 'grey',                  # Or specific grey like '#7f7f7f'\n",
                "        'male-stereotyped': 'tab:blue',     # Standard blue\n",
                "        'neutral (proxy)': 'darkgrey',      # Slightly different grey for proxy\n",
                "        'female-stereotyped': 'tab:red',      # Standard red\n",
                "        'male-stereotyped (proxy)': 'lightsteelblue', # Lighter blue for proxy\n",
                "         # Add any other categories if they exist in your data\n",
                "    }\n",
                "    # Define centroid colors/markers (using hatching is complex, mimic with face/edge color)\n",
                "    CENTROID_COLORS = ['#ff7f0e', '#1f77b4'] # Orange for Cluster 0, Blue for Cluster 1\n",
                "\n",
                "    # --- Create Plot ---\n",
                "    try:\n",
                "        plt.figure(figsize=(16, 14)) # Use a larger figure size similar to the reference\n",
                "        sns.set_style(\"whitegrid\")\n",
                "\n",
                "        # --- Plot Data Points by Stereotype ---\n",
                "        # Create the scatter plot using hue and the defined palette\n",
                "        scatter_plot = sns.scatterplot(\n",
                "            data=df_meta,\n",
                "            x='PC1',\n",
                "            y='PC2',\n",
                "            hue='bls_label',    # Color points by stereotype label\n",
                "            palette=STEREOTYPE_COLORS_FIG7, # Use the specific palette\n",
                "            s=180,              # Slightly larger point size\n",
                "            alpha=0.8,\n",
                "            edgecolor='black',  # Add black edge to points for definition\n",
                "            linewidth=0.5,\n",
                "            legend='full'       # Ensure all hue levels appear in legend initially\n",
                "        )\n",
                "\n",
                "        # --- Add Occupation Labels ---\n",
                "        for i in range(df_meta.shape[0]):\n",
                "            plt.text(\n",
                "                x=df_meta['PC1'][i] + 0.01, # Small offset to avoid overlap\n",
                "                y=df_meta['PC2'][i] + 0.01,\n",
                "                s=df_meta['occupation'][i],\n",
                "                # Pass font properties as individual arguments:\n",
                "                color='black',\n",
                "                fontsize=11,  # Use 'fontsize' instead of 'size'\n",
                "                alpha=0.9\n",
                "            )\n",
                "        # --- Plot Cluster Centroids ---\n",
                "        # Ensure centroid_pca has the right shape (NUM_CLUSTERS, 2)\n",
                "        if 'centroid_pca' in locals() and centroid_pca.shape == (NUM_CLUSTERS, 2):\n",
                "            centroid_handles = []\n",
                "            centroid_labels = []\n",
                "            for i in range(NUM_CLUSTERS):\n",
                "                # Plot each centroid with its specific color and label\n",
                "                handle = plt.scatter(\n",
                "                    centroid_pca[i, 0],\n",
                "                    centroid_pca[i, 1],\n",
                "                    marker=CENTROID_MARKER,\n",
                "                    s=CENTROID_SIZE * 2, # Make centroids significantly larger\n",
                "                    label=f'Cluster {i}.0 Center', # Label matching figure\n",
                "                    # Mimic hatching: use facecolor for main color, edgecolor black\n",
                "                    facecolor=CENTROID_COLORS[i],\n",
                "                    edgecolor='black',\n",
                "                    linewidth=1.5, # Thicker edge\n",
                "                    zorder=5 # Ensure centroids are plotted on top\n",
                "                )\n",
                "                centroid_handles.append(handle)\n",
                "                centroid_labels.append(f'Cluster {i}.0 Center')\n",
                "        else:\n",
                "             print(\"Warning: Centroid PCA coordinates not found or have incorrect shape. Skipping centroid plotting.\")\n",
                "             centroid_handles, centroid_labels = [], []\n",
                "\n",
                "\n",
                "        # --- Final Touches ---\n",
                "        plt.title('PCA of Occupation Embeddings with Gender Stereotypes', fontsize=18)\n",
                "        plt.xlabel('First Principal Component', fontsize=14)\n",
                "        plt.ylabel('Second Principal Component', fontsize=14)\n",
                "\n",
                "        # --- Improve Legend ---\n",
                "        # Get handles and labels from the main scatter plot (stereotypes)\n",
                "        current_handles, current_labels = scatter_plot.get_legend_handles_labels()\n",
                "\n",
                "        # Combine stereotype handles/labels with centroid handles/labels\n",
                "        # Filter out potential title labels if seaborn added them\n",
                "        filtered_handles = []\n",
                "        filtered_labels = []\n",
                "        for h, l in zip(current_handles, current_labels):\n",
                "            if l in STEREOTYPE_COLORS_FIG7: # Keep only labels that match our defined stereotypes\n",
                "                 filtered_handles.append(h)\n",
                "                 filtered_labels.append(l)\n",
                "\n",
                "        # Add the centroid handles/labels\n",
                "        final_handles = filtered_handles + centroid_handles\n",
                "        final_labels = filtered_labels + centroid_labels\n",
                "\n",
                "        # Create the final legend\n",
                "        plt.legend(handles=final_handles, labels=final_labels, title=\"Gender Stereotype\", loc=\"upper right\", fontsize=12, title_fontsize=14)\n",
                "\n",
                "\n",
                "        # Optional: Add dashed circles around centroids (requires matplotlib.patches)\n",
                "        try:\n",
                "            import matplotlib.patches as mpatches\n",
                "            if 'centroid_pca' in locals() and centroid_pca.shape == (NUM_CLUSTERS, 2):\n",
                "                 for i in range(NUM_CLUSTERS):\n",
                "                     # Adjust radius as needed based on cluster spread\n",
                "                     circle_radius = 1.5 # Example radius, tune this value\n",
                "                     circle = mpatches.Circle((centroid_pca[i, 0], centroid_pca[i, 1]),\n",
                "                                               radius=circle_radius,\n",
                "                                               fill=False,\n",
                "                                               linestyle='--',\n",
                "                                               edgecolor='gray', # Use gray for dashed circle\n",
                "                                               linewidth=1.5,\n",
                "                                               alpha=0.7)\n",
                "                     plt.gca().add_patch(circle)\n",
                "        except ImportError:\n",
                "            print(\"matplotlib.patches not available, skipping centroid circles.\")\n",
                "        except Exception as e_circle:\n",
                "             print(f\"Could not draw centroid circles: {e_circle}\")\n",
                "\n",
                "\n",
                "        plt.tight_layout() # Adjust layout automatically\n",
                "\n",
                "        # Save the plot\n",
                "        plt.savefig(PCA_PLOT_OUTPUT_PNG, dpi=300, bbox_inches='tight')\n",
                "        print(f\"\\nPCA scatter plot saved successfully to {PCA_PLOT_OUTPUT_PNG}\")\n",
                "        plt.close() # Close the plot figure\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error generating PCA scatter plot: {e}\")\n",
                "        plt.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c28ba4b1",
            "metadata": {},
            "source": [
                "## 8. Analyze Cluster Composition (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "afe5ffb2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Cluster Composition (Counts):\n",
                        "bls_label  female-stereotyped  male-stereotyped  male-stereotyped (proxy)  \\\n",
                        "cluster                                                                     \n",
                        "0                           1                 2                         1   \n",
                        "1                           5                 3                         0   \n",
                        "\n",
                        "bls_label  neutral  neutral (proxy)  \n",
                        "cluster                              \n",
                        "0                6                1  \n",
                        "1                5                2  \n"
                    ]
                }
            ],
            "source": [
                "if 'cluster' in df_meta.columns and 'bls_label' in df_meta.columns:\n",
                "    # Contingency table: Cluster vs Stereotype Label\n",
                "    contingency_table = pd.crosstab(df_meta['cluster'], df_meta['bls_label'])\n",
                "    print(\"\\nCluster Composition (Counts):\")\n",
                "    print(contingency_table)\n",
                "\n",
                "    # Optional: Percentages within each cluster\n",
                "    # contingency_percent = contingency_table.apply(lambda r: r/r.sum() * 100, axis=1)\n",
                "    # print(\"\\nCluster Composition (% within cluster):\")\n",
                "    # print(contingency_percent.round(1))\n",
                "    \n",
                "else:\n",
                "    print(\"Skipping cluster composition analysis: 'cluster' or 'bls_label' column missing.\")"
            ]
        }
    ],
    "metadata": {
        "jupytext": {
            "encoding": "# -*- coding: utf-8 -*-"
        },
        "kernelspec": {
            "display_name": "llm_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
